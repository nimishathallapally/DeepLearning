{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5048f3",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dc4c9",
   "metadata": {},
   "source": [
    "### NAME   \n",
    "#### Thallapally Nimisha\n",
    "\n",
    "### RollNo  \n",
    "#### CS22B1082\n",
    "\n",
    "### Date  \n",
    "#### 20/01/2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd62b3",
   "metadata": {},
   "source": [
    "### Question 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4b822",
   "metadata": {},
   "source": [
    "### Do not use inbuilt functions for perceptron.\n",
    "\n",
    "### Implement the Perceptron algorithm from scratch in Python\n",
    "- Initialize the weights with [0 0 0] and a learning rate of 0.0001.\n",
    "- For each iteration, calculate the output of the Perceptron for each input in the training set.\n",
    "- Use MSE to computer the error for all samples\n",
    "- Update the weights using the gradient descent procedure.\n",
    "- Repeat the above steps until the Perceptron converges or a maximum number of iterations is reached.\n",
    "- Test the trained Perceptron on a separate test set, explain how you came up with the test set.\n",
    "- Use the step function as an  activation function in the output layer\n",
    "\n",
    "- Use the IRIS Dataset for the above, considering all four features: sepal length, sepal width, petal length, and petal width, but only two classes -  Setosa, and Versicolor.  Drop the feature vectors of the other class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8257363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fbb27129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "df = pd.read_csv('iris.csv')\n",
    "\n",
    "# Filter for Iris-setosa and Iris-virginica\n",
    "df = df[(df['Species'] == 'Iris-setosa') | (df['Species'] == 'Iris-versicolor')]\n",
    "\n",
    "# Create features and labels\n",
    "data = df[['PetalLengthCm', 'PetalWidthCm' ,'SepalLengthCm','SepalWidthCm']].values\n",
    "y = df['Species'].values\n",
    "\n",
    "# Create an array similar to 'data'\n",
    "# Map the species to 0 and 1\n",
    "y_mapped = np.where(y == 'Iris-setosa', 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3052a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2, 5.1, 3.5],\n",
       "       [1.4, 0.2, 4.9, 3. ],\n",
       "       [1.3, 0.2, 4.7, 3.2],\n",
       "       [1.5, 0.2, 4.6, 3.1],\n",
       "       [1.4, 0.2, 5. , 3.6],\n",
       "       [1.7, 0.4, 5.4, 3.9],\n",
       "       [1.4, 0.3, 4.6, 3.4],\n",
       "       [1.5, 0.2, 5. , 3.4],\n",
       "       [1.4, 0.2, 4.4, 2.9],\n",
       "       [1.5, 0.1, 4.9, 3.1],\n",
       "       [1.5, 0.2, 5.4, 3.7],\n",
       "       [1.6, 0.2, 4.8, 3.4],\n",
       "       [1.4, 0.1, 4.8, 3. ],\n",
       "       [1.1, 0.1, 4.3, 3. ],\n",
       "       [1.2, 0.2, 5.8, 4. ],\n",
       "       [1.5, 0.4, 5.7, 4.4],\n",
       "       [1.3, 0.4, 5.4, 3.9],\n",
       "       [1.4, 0.3, 5.1, 3.5],\n",
       "       [1.7, 0.3, 5.7, 3.8],\n",
       "       [1.5, 0.3, 5.1, 3.8],\n",
       "       [1.7, 0.2, 5.4, 3.4],\n",
       "       [1.5, 0.4, 5.1, 3.7],\n",
       "       [1. , 0.2, 4.6, 3.6],\n",
       "       [1.7, 0.5, 5.1, 3.3],\n",
       "       [1.9, 0.2, 4.8, 3.4],\n",
       "       [1.6, 0.2, 5. , 3. ],\n",
       "       [1.6, 0.4, 5. , 3.4],\n",
       "       [1.5, 0.2, 5.2, 3.5],\n",
       "       [1.4, 0.2, 5.2, 3.4],\n",
       "       [1.6, 0.2, 4.7, 3.2],\n",
       "       [1.6, 0.2, 4.8, 3.1],\n",
       "       [1.5, 0.4, 5.4, 3.4],\n",
       "       [1.5, 0.1, 5.2, 4.1],\n",
       "       [1.4, 0.2, 5.5, 4.2],\n",
       "       [1.5, 0.1, 4.9, 3.1],\n",
       "       [1.2, 0.2, 5. , 3.2],\n",
       "       [1.3, 0.2, 5.5, 3.5],\n",
       "       [1.5, 0.1, 4.9, 3.1],\n",
       "       [1.3, 0.2, 4.4, 3. ],\n",
       "       [1.5, 0.2, 5.1, 3.4],\n",
       "       [1.3, 0.3, 5. , 3.5],\n",
       "       [1.3, 0.3, 4.5, 2.3],\n",
       "       [1.3, 0.2, 4.4, 3.2],\n",
       "       [1.6, 0.6, 5. , 3.5],\n",
       "       [1.9, 0.4, 5.1, 3.8],\n",
       "       [1.4, 0.3, 4.8, 3. ],\n",
       "       [1.6, 0.2, 5.1, 3.8],\n",
       "       [1.4, 0.2, 4.6, 3.2],\n",
       "       [1.5, 0.2, 5.3, 3.7],\n",
       "       [1.4, 0.2, 5. , 3.3],\n",
       "       [4.7, 1.4, 7. , 3.2],\n",
       "       [4.5, 1.5, 6.4, 3.2],\n",
       "       [4.9, 1.5, 6.9, 3.1],\n",
       "       [4. , 1.3, 5.5, 2.3],\n",
       "       [4.6, 1.5, 6.5, 2.8],\n",
       "       [4.5, 1.3, 5.7, 2.8],\n",
       "       [4.7, 1.6, 6.3, 3.3],\n",
       "       [3.3, 1. , 4.9, 2.4],\n",
       "       [4.6, 1.3, 6.6, 2.9],\n",
       "       [3.9, 1.4, 5.2, 2.7],\n",
       "       [3.5, 1. , 5. , 2. ],\n",
       "       [4.2, 1.5, 5.9, 3. ],\n",
       "       [4. , 1. , 6. , 2.2],\n",
       "       [4.7, 1.4, 6.1, 2.9],\n",
       "       [3.6, 1.3, 5.6, 2.9],\n",
       "       [4.4, 1.4, 6.7, 3.1],\n",
       "       [4.5, 1.5, 5.6, 3. ],\n",
       "       [4.1, 1. , 5.8, 2.7],\n",
       "       [4.5, 1.5, 6.2, 2.2],\n",
       "       [3.9, 1.1, 5.6, 2.5],\n",
       "       [4.8, 1.8, 5.9, 3.2],\n",
       "       [4. , 1.3, 6.1, 2.8],\n",
       "       [4.9, 1.5, 6.3, 2.5],\n",
       "       [4.7, 1.2, 6.1, 2.8],\n",
       "       [4.3, 1.3, 6.4, 2.9],\n",
       "       [4.4, 1.4, 6.6, 3. ],\n",
       "       [4.8, 1.4, 6.8, 2.8],\n",
       "       [5. , 1.7, 6.7, 3. ],\n",
       "       [4.5, 1.5, 6. , 2.9],\n",
       "       [3.5, 1. , 5.7, 2.6],\n",
       "       [3.8, 1.1, 5.5, 2.4],\n",
       "       [3.7, 1. , 5.5, 2.4],\n",
       "       [3.9, 1.2, 5.8, 2.7],\n",
       "       [5.1, 1.6, 6. , 2.7],\n",
       "       [4.5, 1.5, 5.4, 3. ],\n",
       "       [4.5, 1.6, 6. , 3.4],\n",
       "       [4.7, 1.5, 6.7, 3.1],\n",
       "       [4.4, 1.3, 6.3, 2.3],\n",
       "       [4.1, 1.3, 5.6, 3. ],\n",
       "       [4. , 1.3, 5.5, 2.5],\n",
       "       [4.4, 1.2, 5.5, 2.6],\n",
       "       [4.6, 1.4, 6.1, 3. ],\n",
       "       [4. , 1.2, 5.8, 2.6],\n",
       "       [3.3, 1. , 5. , 2.3],\n",
       "       [4.2, 1.3, 5.6, 2.7],\n",
       "       [4.2, 1.2, 5.7, 3. ],\n",
       "       [4.2, 1.3, 5.7, 2.9],\n",
       "       [4.3, 1.3, 6.2, 2.9],\n",
       "       [3. , 1.1, 5.1, 2.5],\n",
       "       [4.1, 1.3, 5.7, 2.8]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e02785e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ad39e",
   "metadata": {},
   "source": [
    "### Append Bias term 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e89791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = np.ones((data.shape[0], 1))\n",
    "X = np.hstack((data, new_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1fb44cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2, 5.1, 3.5, 1. ],\n",
       "       [1.4, 0.2, 4.9, 3. , 1. ],\n",
       "       [1.3, 0.2, 4.7, 3.2, 1. ],\n",
       "       [1.5, 0.2, 4.6, 3.1, 1. ],\n",
       "       [1.4, 0.2, 5. , 3.6, 1. ],\n",
       "       [1.7, 0.4, 5.4, 3.9, 1. ],\n",
       "       [1.4, 0.3, 4.6, 3.4, 1. ],\n",
       "       [1.5, 0.2, 5. , 3.4, 1. ],\n",
       "       [1.4, 0.2, 4.4, 2.9, 1. ],\n",
       "       [1.5, 0.1, 4.9, 3.1, 1. ],\n",
       "       [1.5, 0.2, 5.4, 3.7, 1. ],\n",
       "       [1.6, 0.2, 4.8, 3.4, 1. ],\n",
       "       [1.4, 0.1, 4.8, 3. , 1. ],\n",
       "       [1.1, 0.1, 4.3, 3. , 1. ],\n",
       "       [1.2, 0.2, 5.8, 4. , 1. ],\n",
       "       [1.5, 0.4, 5.7, 4.4, 1. ],\n",
       "       [1.3, 0.4, 5.4, 3.9, 1. ],\n",
       "       [1.4, 0.3, 5.1, 3.5, 1. ],\n",
       "       [1.7, 0.3, 5.7, 3.8, 1. ],\n",
       "       [1.5, 0.3, 5.1, 3.8, 1. ],\n",
       "       [1.7, 0.2, 5.4, 3.4, 1. ],\n",
       "       [1.5, 0.4, 5.1, 3.7, 1. ],\n",
       "       [1. , 0.2, 4.6, 3.6, 1. ],\n",
       "       [1.7, 0.5, 5.1, 3.3, 1. ],\n",
       "       [1.9, 0.2, 4.8, 3.4, 1. ],\n",
       "       [1.6, 0.2, 5. , 3. , 1. ],\n",
       "       [1.6, 0.4, 5. , 3.4, 1. ],\n",
       "       [1.5, 0.2, 5.2, 3.5, 1. ],\n",
       "       [1.4, 0.2, 5.2, 3.4, 1. ],\n",
       "       [1.6, 0.2, 4.7, 3.2, 1. ],\n",
       "       [1.6, 0.2, 4.8, 3.1, 1. ],\n",
       "       [1.5, 0.4, 5.4, 3.4, 1. ],\n",
       "       [1.5, 0.1, 5.2, 4.1, 1. ],\n",
       "       [1.4, 0.2, 5.5, 4.2, 1. ],\n",
       "       [1.5, 0.1, 4.9, 3.1, 1. ],\n",
       "       [1.2, 0.2, 5. , 3.2, 1. ],\n",
       "       [1.3, 0.2, 5.5, 3.5, 1. ],\n",
       "       [1.5, 0.1, 4.9, 3.1, 1. ],\n",
       "       [1.3, 0.2, 4.4, 3. , 1. ],\n",
       "       [1.5, 0.2, 5.1, 3.4, 1. ],\n",
       "       [1.3, 0.3, 5. , 3.5, 1. ],\n",
       "       [1.3, 0.3, 4.5, 2.3, 1. ],\n",
       "       [1.3, 0.2, 4.4, 3.2, 1. ],\n",
       "       [1.6, 0.6, 5. , 3.5, 1. ],\n",
       "       [1.9, 0.4, 5.1, 3.8, 1. ],\n",
       "       [1.4, 0.3, 4.8, 3. , 1. ],\n",
       "       [1.6, 0.2, 5.1, 3.8, 1. ],\n",
       "       [1.4, 0.2, 4.6, 3.2, 1. ],\n",
       "       [1.5, 0.2, 5.3, 3.7, 1. ],\n",
       "       [1.4, 0.2, 5. , 3.3, 1. ],\n",
       "       [4.7, 1.4, 7. , 3.2, 1. ],\n",
       "       [4.5, 1.5, 6.4, 3.2, 1. ],\n",
       "       [4.9, 1.5, 6.9, 3.1, 1. ],\n",
       "       [4. , 1.3, 5.5, 2.3, 1. ],\n",
       "       [4.6, 1.5, 6.5, 2.8, 1. ],\n",
       "       [4.5, 1.3, 5.7, 2.8, 1. ],\n",
       "       [4.7, 1.6, 6.3, 3.3, 1. ],\n",
       "       [3.3, 1. , 4.9, 2.4, 1. ],\n",
       "       [4.6, 1.3, 6.6, 2.9, 1. ],\n",
       "       [3.9, 1.4, 5.2, 2.7, 1. ],\n",
       "       [3.5, 1. , 5. , 2. , 1. ],\n",
       "       [4.2, 1.5, 5.9, 3. , 1. ],\n",
       "       [4. , 1. , 6. , 2.2, 1. ],\n",
       "       [4.7, 1.4, 6.1, 2.9, 1. ],\n",
       "       [3.6, 1.3, 5.6, 2.9, 1. ],\n",
       "       [4.4, 1.4, 6.7, 3.1, 1. ],\n",
       "       [4.5, 1.5, 5.6, 3. , 1. ],\n",
       "       [4.1, 1. , 5.8, 2.7, 1. ],\n",
       "       [4.5, 1.5, 6.2, 2.2, 1. ],\n",
       "       [3.9, 1.1, 5.6, 2.5, 1. ],\n",
       "       [4.8, 1.8, 5.9, 3.2, 1. ],\n",
       "       [4. , 1.3, 6.1, 2.8, 1. ],\n",
       "       [4.9, 1.5, 6.3, 2.5, 1. ],\n",
       "       [4.7, 1.2, 6.1, 2.8, 1. ],\n",
       "       [4.3, 1.3, 6.4, 2.9, 1. ],\n",
       "       [4.4, 1.4, 6.6, 3. , 1. ],\n",
       "       [4.8, 1.4, 6.8, 2.8, 1. ],\n",
       "       [5. , 1.7, 6.7, 3. , 1. ],\n",
       "       [4.5, 1.5, 6. , 2.9, 1. ],\n",
       "       [3.5, 1. , 5.7, 2.6, 1. ],\n",
       "       [3.8, 1.1, 5.5, 2.4, 1. ],\n",
       "       [3.7, 1. , 5.5, 2.4, 1. ],\n",
       "       [3.9, 1.2, 5.8, 2.7, 1. ],\n",
       "       [5.1, 1.6, 6. , 2.7, 1. ],\n",
       "       [4.5, 1.5, 5.4, 3. , 1. ],\n",
       "       [4.5, 1.6, 6. , 3.4, 1. ],\n",
       "       [4.7, 1.5, 6.7, 3.1, 1. ],\n",
       "       [4.4, 1.3, 6.3, 2.3, 1. ],\n",
       "       [4.1, 1.3, 5.6, 3. , 1. ],\n",
       "       [4. , 1.3, 5.5, 2.5, 1. ],\n",
       "       [4.4, 1.2, 5.5, 2.6, 1. ],\n",
       "       [4.6, 1.4, 6.1, 3. , 1. ],\n",
       "       [4. , 1.2, 5.8, 2.6, 1. ],\n",
       "       [3.3, 1. , 5. , 2.3, 1. ],\n",
       "       [4.2, 1.3, 5.6, 2.7, 1. ],\n",
       "       [4.2, 1.2, 5.7, 3. , 1. ],\n",
       "       [4.2, 1.3, 5.7, 2.9, 1. ],\n",
       "       [4.3, 1.3, 6.2, 2.9, 1. ],\n",
       "       [3. , 1.1, 5.1, 2.5, 1. ],\n",
       "       [4.1, 1.3, 5.7, 2.8, 1. ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edb4c2",
   "metadata": {},
   "source": [
    "### Train Test Split (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "62d10eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Setosa and Virginica samples\n",
    "setosa_samples = X[y_mapped == 0]\n",
    "versicolor_samples = X[y_mapped == 1]\n",
    "\n",
    "# Manually split each class into training (80%) and testing (20%)\n",
    "setosa_train = setosa_samples[:int(0.8 * len(setosa_samples))]\n",
    "setosa_test = setosa_samples[int(0.8 * len(setosa_samples)):]\n",
    "\n",
    "versicolor_train = versicolor_samples[:int(0.8 * len(versicolor_samples))]\n",
    "versicolor_test = versicolor_samples[int(0.8 * len(versicolor_samples)):]\n",
    "\n",
    "# Concatenate the corresponding training and testing sets\n",
    "X_train = np.vstack((setosa_train, versicolor_train))\n",
    "y_train = np.hstack((np.zeros(len(setosa_train)), np.ones(len(versicolor_train))))\n",
    "\n",
    "X_test = np.vstack((setosa_test, versicolor_test))\n",
    "y_test = np.hstack((np.zeros(len(setosa_test)), np.ones(len(versicolor_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b73984",
   "metadata": {},
   "source": [
    "### Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d69f0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(X_train, y_train, learning_rate=0.0001, max_iter=1000):\n",
    "    weights = np.zeros(X.shape[1]) # Initialize weights (including bias) with 4 elements (1 for bias + 3 features)\n",
    "    for epoch in range(max_iter):\n",
    "        total_error = 0\n",
    "        for i in range(len(X_train)):\n",
    "            xi = X_train[i]\n",
    "            yi = y_train[i]\n",
    "            # Perceptron output using step function\n",
    "            output = np.dot(xi, weights) >= 0  # Step function (output = 1 if >= 0, else 0)\n",
    "            error = yi - output  # MSE error for this sample\n",
    "            weights += learning_rate * error * xi  # Gradient descent update\n",
    "            total_error += error**2  \n",
    "        if total_error == 0:\n",
    "            print(f\"Converged after {epoch+1} iterations.\")\n",
    "            break\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab14ef6",
   "metadata": {},
   "source": [
    "### Perceptron Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bf4581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 4 iterations.\n"
     ]
    }
   ],
   "source": [
    "weights = perceptron_train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c575412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00052,  0.00022, -0.00013, -0.00041, -0.0001 ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9964c",
   "metadata": {},
   "source": [
    "### Perceptron testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed931ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_predict(X, weights):\n",
    "    return np.dot(X, weights) >= 0  # Step function prediction\n",
    "\n",
    "# Test the perceptron on the test set\n",
    "y_pred_test = perceptron_predict(X_test, weights)\n",
    "y_pred_train = perceptron_predict(X_train, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06daff",
   "metadata": {},
   "source": [
    "### Accuracy of training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5d54699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 100.00%\n",
      "Accuracy on the test set: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = np.mean(y_pred_train == y_train) * 100\n",
    "print(f\"Accuracy on the training set: {train_accuracy:.2f}%\")\n",
    "\n",
    "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
    "print(f\"Accuracy on the test set: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e25c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
